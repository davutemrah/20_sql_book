---
title: "power analysis"
author: "dea"
date: "`r Sys.Date()`"
output: html_document
---


## Power Analysis

### Overview

Power analysis is an important aspect of experimental design. It allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. Conversely, it allows us to determine the probability of detecting an effect of a given size with a given level of confidence, under sample size constraints. If the probability is unacceptably low, we would be wise to alter or abandon the experiment.

The following four quantities have an intimate relationship:

a. **sample size**

b. **effect size**

c. **significance level** = P(Type I error) = probability of finding an effect that is not there

d. **power** = 1 - P(Type II error) = probability of finding an effect that is there


Given any three, we can determine the fourth.



### Power Analysis in R
The `pwr` package develped by St√©phane Champely, impliments power analysis as outlined by Cohen (1988). Some of the more important functions are listed below.

function	power calculations for
`pwr.2p.test`	two proportions (equal n)
`pwr.2p2n.test`	two proportions (unequal n)
`pwr.anova.test`	balanced one way ANOVA
`pwr.chisq.test`	chi-square test
`pwr.f2.test`	general linear model
`pwr.p.test`	proportion (one sample)
`pwr.r.test`	correlation
`pwr.t.test`	t-tests (one sample, 2 sample, paired)
`pwr.t2n.test`	t-test (two samples with unequal n)

For each of these functions, you enter three of the four quantities (effect size, sample size, significance level, power) and the fourth is calculated.

The significance level defaults to 0.05. Therefore, to calculate the significance level, given an effect size, sample size, and power, use the option "sig.level=NULL".

Specifying an effect size can be a daunting task. ES formulas and Cohen's suggestions (based on social science research) are provided below. Cohen's suggestions should only be seen as very rough guidelines. Your own subject matter experience should be brought to bear.

(To explore confidence intervals and drawing conclusions from samples try this interactive course on the foundations of inference.)

#### t-tests

For t-tests, use the following functions:


pwr.t2n.test(n1 = , n2= , d = , sig.level =, power = ) where n1 and n2 are the sample sizes.

For t-tests, the effect size is assessed as

d = |mu1 - mu2|/ var

Cohen suggests that d values of 0.2, 0.5, and 0.8 represent small, medium, and large effect sizes respectively.

You can specify alternative="two.sided", "less", or "greater" to indicate a two-tailed, or one-tailed test. A two tailed test is the default.


The `pwr.t.test` function in R is used to perform power analysis for t-tests. It helps you determine the sample size needed to achieve a certain level of power for a specified effect size and significance level. Here's a simple example using `pwr.t.test`:

Let's say you want to perform a two-sample t-test to compare the means of two groups. You want to know how many samples per group you need to achieve 80% power to detect a difference of 2 units between the group means, assuming a standard deviation of 5 and a significance level of 0.05.

```{R}
# Load the pwr package
library(pwr)

# pwr.t.test(n = NULL, d = NULL, 
#    sig.level = 0.05, power = NULL, 
#    type = c("two.sample", "one.sample", "paired"),
#    alternative = c("two.sided", "less", "greater"))`
    
# where n is the sample size, d is the effect size, and type indicates a two-sample t-test, # # one-sample t-test or paired t-test. If you have unequal sample sizes, use


# Set parameters for the power analysis

## effect_size = abs(mean1 - mean2)/sd_pooled

effect_size <- .2 # Difference in means
sd_pooled <- 5    # Pooled standard deviation
alpha <- 0.05      # Significance level
power <- 0.80      # Desired power

# Perform power analysis
result <- pwr.t.test(d = effect_size, 
                     #sd = sd_pooled, 
                     sig.level = alpha, 
                     power = power, 
                     type = "two.sample")

# Display the result
print(result)
```

In this example:

- `d` is the effect size (difference in means divided by the standard deviation).
- `sd` is the pooled standard deviation.
- `sig.level` is the significance level (usually set to 0.05).
- `power` is the desired power level.

The `type` argument specifies the type of t-test, and in this case, it's a "two.sample" t-test.

The `pwr.t.test` function will return a list with information about the power analysis, including the sample size needed per group.

```{r}
# pwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL,
#  alternative = c("two.sided", 
#         "less","greater"))

pwr.t2n.test(n1=100, d=0.5, sig.level = 0.05, power = 0.8)
```

```{r}
# pwr.t2n.test(n1 = NULL, n2= NULL, d = NULL, sig.level = 0.05, power = NULL,
#  alternative = c("two.sided", 
#         "less","greater"))

pwr.t2n.test(n1=100, n2=10, d=.5, sig.level = 0.05)
```

1. Required control size increases as effect size (d) decreases

2. Required control size increases as significance level decreases


### Some Examples

```{r}
library(pwr)

# For a one-way ANOVA comparing 5 groups, calculate the
# sample size needed in each group to obtain a power of
# 0.80, when the effect size is moderate (0.25) and a
# significance level of 0.05 is employed.

pwr.anova.test(k=5,f=.25,sig.level=.05,power=.8)

# What is the power of a one-tailed t-test, with a
# significance level of 0.01, 25 people in each group,
# and an effect size equal to 0.75?

pwr.t.test(n=25,d=0.75,sig.level=.01,alternative="greater")

# Using a two-tailed test proportions, and assuming a
# significance level of 0.01 and a common sample size of
# 30 for each proportion, what effect size can be detected
# with a power of .75?

pwr.2p.test(n=30,sig.level=0.01,power=0.75)
```

```{r}
library(pwr)

# range of correlations
r <- seq(.1,.5,.01)
nr <- length(r)

# power values
p <- seq(.4,.9,.1)
np <- length(p)

# obtain sample sizes
samsize <- array(numeric(nr*np), dim=c(nr,np))
for (i in 1:np){
  for (j in 1:nr){
    result <- pwr.r.test(n = NULL, r = r[j],
    sig.level = .05, power = p[i],
    alternative = "two.sided")
    samsize[j,i] <- ceiling(result$n)
  }
}

# set up graph
xrange <- range(r)
yrange <- round(range(samsize))
colors <- rainbow(length(p))
plot(xrange, yrange, type="n",
  xlab="Correlation Coefficient (r)",
  ylab="Sample Size (n)" )

# add power curves
for (i in 1:np){
  lines(r, samsize[,i], type="l", lwd=2, col=colors[i])
}

# add annotation (grid lines, title, legend)
abline(v=0, h=seq(0,yrange[2],50), lty=2, col="grey89")
abline(h=0, v=seq(xrange[1],xrange[2],.02), lty=2,
   col="grey89")
title("Sample Size Estimation for Correlation Studies\n
  Sig=0.05 (Two-tailed)")
legend("topright", title="Power",
as.character(p),
   fill=colors)
```



